{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21장. 훈련된 모델 저장과 복원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북을 주피터 노트북 뷰어(nbviewer.jupyter.org)로 보거나 구글 코랩(colab.research.google.com)에서 실행할 수 있습니다.\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/rickiepark/machine-learning-with-python-cookbook/blob/master/21.ipynb\"><img src=\"https://jupyter.org/assets/main-logo.svg\" width=\"28\" />주피터 노트북 뷰어로 보기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/machine-learning-with-python-cookbook/blob/master/21.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.1 사이킷런 모델을 저장하고 복원하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "import joblib\n",
    "\n",
    "# 데이터를 로드합니다.\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 결정 트리 분류기 객체를 만듭니다.\n",
    "classifer = RandomForestClassifier()\n",
    "\n",
    "# 모델을 훈련합니다.\n",
    "model = classifer.fit(features, target)\n",
    "\n",
    "# 모델을 피클 파일로 저장합니다.\n",
    "joblib.dump(model, \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일에서 모델을 복원합니다.\n",
    "classifer = joblib.load(\"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 샘플을 만듭니다.\n",
    "new_observation = [[ 5.2,  3.2,  1.1,  0.1]]\n",
    "\n",
    "# 샘플의 클래스를 예측합니다.\n",
    "classifer.predict(new_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_0.22.1.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import sklearn\n",
    "\n",
    "# 사이킷런 버전을 구합니다.\n",
    "scikit_version = sklearn.__version__\n",
    "\n",
    "# 모델을 피클 파일로 저장합니다.\n",
    "joblib.dump(model, \"model_{version}.pkl\".format(version=scikit_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.2 케라스 모델을 저장하고 복원하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import load_model\n",
    "\n",
    "# 랜덤 시드를 지정합니다.\n",
    "np.random.seed(0)\n",
    "\n",
    "# 원하는 특성 개수를 설정합니다.\n",
    "number_of_features = 1000\n",
    "\n",
    "# 영화 리뷰 데이터와 타깃 벡터를 로드합니다.\n",
    "(train_data, train_target), (test_data, test_target) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# 영화 리뷰 데이터를 원-핫 인코딩된 특성 행렬로 변환합니다.\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "train_features = tokenizer.sequences_to_matrix(train_data, mode=\"binary\")\n",
    "test_features = tokenizer.sequences_to_matrix(test_data, mode=\"binary\")\n",
    "\n",
    "# 신경망을 모델을 만듭니다.\n",
    "network = models.Sequential()\n",
    "\n",
    "# ReLU 활성화 함수를 사용한 완전 연결 층을 추가합니다.\n",
    "network.add(layers.Dense(units=16,\n",
    "                         activation=\"relu\",\n",
    "                         input_shape=(number_of_features,)))\n",
    "\n",
    "# 시그모이드 활성화 함수를 사용한 완전 연결 층을 추가합니다.\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# 신경망 모델의 설정을 완료합니다.\n",
    "network.compile(loss=\"binary_crossentropy\", # 크로스 엔트로피\n",
    "                optimizer=\"rmsprop\", # 최적화 알고리즘\n",
    "                metrics=[\"accuracy\"]) # 정확도\n",
    "\n",
    "# 신경망을 훈련합니다.\n",
    "history = network.fit(train_features, # 특성\n",
    "                      train_target, # 타깃 벡터\n",
    "                      epochs=3, # 에포크 횟수\n",
    "                      verbose=0, # 출력 없음\n",
    "                      batch_size=100, # 배치 샘플 수\n",
    "                      validation_data=(test_features, test_target)) # 테스트 데이터\n",
    "\n",
    "# 신경망 모델을 저장합니다.\n",
    "network.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 모델을 복원합니다.\n",
    "network = load_model(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
